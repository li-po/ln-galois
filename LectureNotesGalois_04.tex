\section{Summary}
We have been considering $[L:K]<\infty$, a finite field extension, and we have defined separability. We have seen that, if $L$ is generated over $K$ by a finite number of separable elements, $\alpha_1,\cdots\alpha_r$, $\iff$ the number of $\text{Hom}_K(L,\overbar{K})=[L:K]$. (In general this number of homomorphisms is less or equal than the degree.) 

These number of homomorphisms, we have called it "the separable degree" of L over K, $[L:K]_{\text{sep}}$. If $L$ was generated by only one element $\alpha$, $L=K(\alpha)$, this was clear since those homomorphisms were taking $\alpha$ to other roots of the minimal polynomial. And so, the number of homomorphisms was equal to the number of roots of the minimal polynomial. And in general, one can use induction and the multiplicativity over the degree (linear algebra) and the number of homomorphisms (extension theorem). 

A separable extension was exactly an extension which had the right number of homomorphisms into the algebraic closure. In the future we will characterize separability in terms of tensor products.

%----------------------------------------------------------------------
\chapter{Tensor product. Structure of finite K-algebras}

This will be a general digression which does not have much to do with field extensions.

\section{Definition of tensor product}
We consider a ring $A$ and two $A$-modules, $M$ and $N$. The tensor product $M$ tensor $N$ over $A$, $M\otimes_A N$, is another $A$-module together with an $A$-bilinear map $\phi:M\times N\to M\otimes_A N$ with the following universal property: if $P$ is any $A$-module and $f:M\times N\to P$ $A$-bilinear (i.e. $\forall m$, $f_m:N\to P$,$n\mapsto f(m,n)$ and $\forall n$, $f_n:M\to P$,$m\mapsto f(m,n)$ are $A$-module homomorphisms (also $A$-linear homomorphisms of $A$-modules) then there exists a unique homomorphism of $A$-modules $\widetilde{f}:M\otimes_A N\to P$, such $f=\widetilde{f}\circ \phi$. This property characterizes $(\phi,M\otimes N)$ because if there is another pair $(\overbar{\phi},\overbar{M\otimes N})$ with this property, then, by the very definition, we have mutually inverse homomorphisms of $A$-modules between our tensor products. The unity of such a thing follows directly from the definition. 

Why does such a thing exist? One has to give a construction. The construction can be as follows: so, consider 
\[
\mathcal{E}=\left\{\text{maps }M\times N \to A\text{, 0 almost everywhere}\right\}
\]
(as sets, without any structure). What means almost everywhere? Outside of a finite set.  For instance, we can take some kind of delta functions. $\delta_{m,n}:M\times N\to A$, $\delta_{m,n}(m,n)=1$ and $\delta_{m,n}(m',n')=0$, $\forall (m',n')\neq(m,n)$. Then $\mathcal{E}$ is a free $A$-module with base $\delta_{m,n}$. Now we have a map of sets $M \times N \to E$, $(m,n)\to \delta_{m,n}$. We can make it bilinear by changing $\mathcal{E}$. We can take a quotient. Take $\mathcal{F}\subset \mathcal{E}$ a submodule generated by $\delta_{m+m',n}-\delta_{m,n}-\delta_{m',n}$, $\delta_{m,n+n'}-\delta_{m,n}-\delta_{m,n'}$,  $\delta_{am,n}-a\delta_{m,n}$, $\delta_{m,an}-a\delta_{m,n}$. Then the map $M \times N \to \mathcal{E}/\mathcal{F}$ is bilinear. And it is very easy to see that this has the desired universal property.

\section{Tensor product of modules}

If we have any bilinear map $f:M \times N \to P$, we can also define a map $\mathcal{E} \to P$, $\delta_{m,n} \to f(m,n)$. When the map $f$ is bilinear, the map $\mathcal{E}\to P$ must factor through the quotient, $\mathcal{E}/\mathcal{F}$, as f is bilinear. This map must be zero on $\mathcal{F}$.  So this factorization is determined by images of $\delta_{m,n}$. So this is unique. So we can call it $\phi$ ($M\times N\to \mathcal{E}/\mathcal{F}$) and we can identify $\mathcal{E}/\mathcal{F}$ (?) with $M \otimes N$. 

$M\times N$ is generated by $m\otimes n$ ($\delta_{m,n}$'s mod $F$). In fact any element of my tensor product is a finite sum of such things. Remark: Not equal to $\left\{ m\otimes n, m\in M, n \in N\right\}$, but $\forall x\in M\otimes N$, $x=\sum_{i=1}^n m_i\otimes n_i$.

Why haven't we just defined the tensor product by this construction? Why are we talking of this universal property? And the answer is because the advantage of the universal property is that the proofs become easy. 

For example, if we have to prove commutativity, let us prove that $M \otimes_A N\cong N \otimes_A M$. Then it is very elegant with the universal property. Indeed $M times N \to N  \otimes_A M$, $(m, n) \mapsto n \otimes m$ is bilinear. Therefore, it factors through the tensor product. We have $\alpha:M \otimes_A N \to N \otimes_A M$. In the same way obtain the inverse map of $\alpha$, in the other direction. 

In the same way we prove, for instance, that $A \otimes_A M \cong M$ (isomorphic).

More seriously: We have seen that, if $M$ is generated by $e_1, \cdots e_n$, and $N$ is generated by $\epsilon_1, \cdots \epsilon_m$, $\implies$ $M\otimes_A N$ is generated by  $e_i\otimes\epsilon_j$.
We can also prove: 

\begin{proposition}
If $e_1, \cdots e_n$ bases of $M$ and $\epsilon_1, \cdots \epsilon_m$ is a basis of $M$, and $\epsilon_1, \cdots \epsilon_n$ is a basis of $N$, then $e_i\otimes \epsilon_j$, where $1 \leq i\leq n$ and $1 \leq j\leq m$, is a basis of $M \otimes_A N$. And this is easily done with the universal property. 
\end{proposition}

\begin{proof}
Let us define a bilinear map $f_{i_0,j_0}:M \times N \to A$, $\left(\sum a_ie_i,\sum b_j\epsilon_j\right)\mapsto a_{i_0}, b_{j_0}$ is bilinear. So it factors through the tensor product $\widetilde{f}_{i_0,j_0}:M\otimes N\to A$, $e_{i_0}\otimes\epsilon_{j_0}\mapsto 1$ and other $e_i\otimes\epsilon_j\mapsto 0$.

So if $\sum_{i,j}\alpha_{ij} e_i\otimes\epsilon_j =0$, then applying this $\widetilde{f}_{i_0,j_0}$, we see that $\alpha_{i_0j_0}= 0$. Doing this for all $i_0$, $j_0$, we conclude that all coefficients are $0$. The tensor product of $K$-vector spaces with basis $e_1, \cdots e_n$ and $\epsilon_1, \cdots \epsilon_m$ is a K-vector space with basis the $e_i\otimes \epsilon_j$. This is how it is often defined. One just introduces formally such a base and builds a vector spaces on this. But it is much better to use this universal property.
\end{proof}

\section{Base change}

One also has other more or less elementary properties of the tensor products. For instance, associativity $(M_1 \otimes_A M_2) \otimes_A M_3\cong M_1 \otimes_A (M_2 \otimes_A M_3)$.  (The easiest way to prove this, is to introduce a triple tensor product $M_1\otimes_A M_2\otimes_A M_3$ as a universal object for trilinear maps and then show that both parts are isomorphic to this object).

Let me talk now about the base change. So, we have a ring $A$. Another ring $B$, which is an $A$-algebra. Also an extension of $A$ as a ring. And let's have also $M$ an A-module. And $N$ and $B$-module. I can make $N$ into $A$-module just forgetting the multiplication by the $B$-module structure. 

You can make a $B$-module of $M$ by considering $B \otimes_A M$. Indeed we can introduce the $B$-module structure on $B \otimes_A M$ by setting $b (b'\otimes m)=bb'\otimes m$.  

\begin{example} \textit{Complexification of a real vector space.}
If you have a complex vector space $\mathbb{C}^n$, then you can make a real vector space $\mathbb{R}^{2n}$ of this just by forgetting the complex structure. If here you had basis $e_1,\cdots e_n$, then you just forget that you can multiply it by imaginary numbers and so, you obtain the basis $e_1,\cdots e_n, ie_1,\cdots ie_n$. But then you forget all together about this $i$ and you redefine them as $v_1=ie_1,\cdots v_n=ie_n$. Now, if you complexify, if you want to make a complex vector space out of $\mathbb{R}^{2n}$. Now, take $\mathbb{C} \otimes \mathbb{R}^{2n}$ with basis of $e_1, \cdots e_n, v_1, \cdots v_n$. (More precisely, one should write, $1\otimes e_1, \cdots 1 \otimes v_n$. Of course, you can also go in the other way. $\mathbb{R}^n$ with basis $e_1 , \cdots e_n$, then make it into a complex vector space by tensoring with $\mathbb{C}$: $\mathbb{C}^n=\mathbb{C}\otimes_{\mathbb{R}} \mathbb{R}^n$. $\mathbb{C}$-basis $1 \otimes e_i$, and then you obtain $\mathbb{R}^{2n}$ (by forgetting the complex structure) with basis $1\otimes e_i$ and $i\otimes e_i$. 
\end{example}

In general, if $M$ is a free $A$-module with base $e_1,\cdots e_n$ and we tensor it up with $B$, $B\otimes_A M$, this will be a free $B$-module with base $1\otimes e_1,\cdots 1\otimes e_n$. We also have a couple of important maps of $A$-modules: $M\to B\otimes_A M$, $m\mapsto 1\otimes m$ and also we have a map in the other direction. $B \otimes_A N\to N$, $b\otimes n \mapsto b_n$.(Recall $N$ is a $B$-module, but the map is of $A$-modules. Of $B$-modules too.) 

The proof is the same as that of the previous proposition: We construct certain bilinear maps and say that those factor over the tensor product and this implies that certain families are linearly independent. 

Now let me formulate a very important theorem. Notations are as before.

\begin{theorem} \textbf{Base change theorem.}

$\text{Hom}_A(M,N)\leftrightarrow\text{Hom}_B(B\otimes_A M,N)$ (bijection, the corresponding groups of homomorphisms are isomorphic).
\end{theorem}

\begin{proof}
We have $M\xrightarrow{\alpha} B \otimes_A M \xrightarrow{f} N$,$f\mapsto f\cdot\alpha$. In one direction, $M\xrightarrow{g} N$, $B\otimes_A M\xrightarrow{\text{id}\otimes g}B\otimes_A N\xrightarrow{\mu}B$ ($b\otimes n \to b_n$). $g\mapsto \mu\cdot(\text{id}\otimes g)$.  And then we check that those maps are mutually inverse.
\end{proof}

\section{Examples. Tensor product of algebras}

So let me give you an example of such a base change which deserves the name of a proposition. 

\begin{proposition}
$I\subset A$ ideal. The ring $B$, the $A$-algebra, will be $A/I \otimes_A M\cong M/IM$.

(The ring $B$, the $A$-algebra, will be $A/I$. And we are going to base change $M$ to an $A/I$-module, then we affirm that this is just $M/IM$. So $IM$ is a submodule of $M$. We take the quotient module, and we affirm this is the same as the base change of $M$ to $A/I$.)
\end{proposition}

\begin{proof}
We can define in one direction the map $M \to A/I \otimes_A M$, $m\mapsto 1\otimes m$. (This is the previous map $\alpha$). Then we remark that this sends $IM$ to $0$, because if we have $im\mapsto 1\otimes im$, where $i\in I$, everything is $A$-linear, so we can put $i$ into the other side: $im\mapsto i\otimes m$. And $i\otimes m=0\otimes m=0$ because now we are in $A/I$. $\implies$ $\alpha$ induces a map $\overbar{\alpha}: M/IM\to A/I\otimes_A M$.

Now in the other direction we apply the \textit{Base change theorem}. Consider the projection $M \to M/IM$ (map of $A$-modules) gives ($B=A/I$) $B\otimes_A M\to M/IM$ a map of $B$-modules. One checks again that this is the inverse of $\overbar{\alpha}$. 
\end{proof}


\begin{example}
Let's take $\mathbb{Z}/2\mathbb{Z}\otimes_{\mathbb{Z}} \mathbb{Z}/3\mathbb{Z}$. What do we obtain? We may consider it as a base change of $\mathbb{Z}/3\mathbb{Z}$ to $\mathbb{Z}/2\mathbb{Z}$. So:
\[
\mathbb{Z}/2\mathbb{Z}\otimes_{\mathbb{Z}} \mathbb{Z}/3\mathbb{Z}\cong 
\bigslant{\mathbb{Z}/3\mathbb{Z}}{(2)\cdot \mathbb{Z}/3\mathbb{Z} }
\]
But $2$ is invertible modulo $3$. Thus This is just $-1$ in fact. But $(2)\cdot \mathbb{Z}/3\mathbb{Z} = \mathbb{Z}/3\mathbb{Z}$. $(2)$ is not a proper ideal in $\mathbb{Z}/3\mathbb{Z}$, it's equal to the whole ring, so the quotient is $0$.
\end{example}

\begin{example}
Another obvious example. If we base change a polynomial ring, we obtain again a polynomial ring only over $B$. $B\otimes_A A[x]\cong B[x]$. This is a very interesting example, if I base change $B\otimes A[x]/(P)$ what do we obtain? We obtain $B[x]/(P)$, but in $B[x]$ (ideal generated by $P$ in $B[x]$.) 
\end{example}


\subsection*{Tensor product of $A$-algebras}

Let fix two $A$-algebras $B$ and $C$. $\alpha: A \to B$ and $\beta: A \to C$, which define the $A$-algebra structure on $B$ and $C$, then we can introduce a new $A$-algebra $B \otimes_A C$. $B \otimes_A C$ is a ring with respect to the following operation $(b\otimes c)\cdot(b'\otimes c')= bb'\otimes c c'$. In fact, this has the following universal property: 
\begin{diagram}
& & B\otimes_A C & \\
& \ruTo^{\phi} & & \luTo^{\psi} & \\
B& & & & C\\
& \luTo^{\alpha} & & \ruTo^{\beta} & \\
& & A & & \\
\end{diagram}
So $\phi: b \mapsto b \otimes 1$, $\psi: c \mapsto 1 \otimes c$.
For any $A$-algebra $D$ one has $\text{Hom}_A(B\otimes_A C, D) \rightleftharpoons \text{Hom}_A(B,D)\times\text{Hom}_A(C,D)$ (bijection). If we have some homomorphism, say $h:B\otimes_A C \to D$, this is the same as giving two homomorphisms, let's say $f:B\to D$ and $g:C\to V$ such that all maps in this diagonal commute. (The diagram commutes.)

So if we have $h$ we can define $f$ and $g$: $h\mapsto (h\cdot \phi,h\cdot \psi)$ and conversely, given $f$ and $g$, can define $h(b \otimes c)= f(b) \cdot g(c)$.

Okay, but I shall not say any more on this, this is just for the general culture. The main point for us is that the tensor product of the $A$-algebras is itself an $A$-algebra by this very simple rule, componentwise multiplication. Let us give an example.

\begin{example}
Consider $\mathbb{C} \otimes_{\mathbb{R}} \mathbb{C}$. How to describe the ring structure? What does it mean? 
\begin{align}
\mathbb{C} & \otimes_{\mathbb{R}} \mathbb{C}\cong \mathbb{C} \otimes 
\bigslant{\mathbb{R}[x]}{(x^2+1)}
\cong 
\bigslant{\mathbb{C}[x]}{(x^2+1)} \\
&\cong 
\bigslant{\mathbb{C}[x]}{(x+i)} \times \bigslant{\mathbb{C}[x]}{(x-i)}\\
&\cong 
\mathbb{C}\times \mathbb{C}
\end{align}
The next to last isomorphism is due to the Chinese remainder theorem.
\end{example}

This ring is not a field. $\mathbb{C}$ is a field but this tensor square has zero divisors, and so not a field. How to identify a zero divisor? The class of $\overbar{x+i}$ is a zero divisor and is represented by $1\otimes \overbar{X}+ i\otimes\overbar{1}$ and in $\mathbb{C}\otimes_{\mathbb{R}} \mathbb{C}$ it is $1\otimes i + i\otimes 1$.

\section{Relatively prime ideals. Chinese remainder theorem}

So, now let me tell you about the structure of a finite algebra over a field. 

\begin{definition}
Let $A$ be a ring. One says that the ideals $I$ and $J$ are \textbf{relatively prime} if they generate $A$.
\end{definition}

\begin{lemma}
\begin{enumerate}
\item If $I, J$ are relatively prime $\implies$ $IJ=I\cap J$.
\item If $I_1,\cdots I_k$ are relatively prime with $J$ $\implies$ so is their product.
\item If $I, J$ are relatively prime $\implies$ so are $I^k$ and $J^l$, $\forall k,l$. 
\end{enumerate}
\end{lemma}

\begin{proof}
1) $IJ\subset I\cap J$ by definition. If we are relatively prime, then we have $1=i + j$ for some $i \in I$ and $j \in J$. Then for any $x\in I\cap J$ we have $x = xi + xj$, with both $xi$ and $xj$ in $IJ$.

2) Let's suppose $k = 2$. The general case is similar. $1 = i_1 + j_1 = i_2 + j_2$, where $i_1 \in I_1$, $i_2 \in I_2$, $j_1\in J$, $j_2 \in J$. $1 = (i_1 + j_1)(i_2 + j_2)=i_1 i_2 + j_1 i_2 + j_2 i_1 + j_1 j_2$. $i_1 i_2\in I_1I_2$ and the other three terms $\in J$. 

3) From 2) by induction. 
\end{proof} 

$K$ field, $A$ finite $K$-algebra ( "finite" means a finite-dimensional vector space). We recall the Chinese remainder theorem. 

\begin{theorem} \textbf{Chinese remainder theorem.}
$I_1,\cdots I_n$ ideals. Consider the map $\pi: A \to A/I_2 \times \cdots \times A/I_n$. $a \mapsto (a\text{ mod }I_1, \cdots, a\text{ mod }I_n)$ ($\text{Ker }\pi=I_1\cap\cdots\cap I_b$). $\pi$ is surjective $\iff$ $I_1,\cdots I_n$ are pairwise relatively prime. And then 
\[
\bigslant{A}{\cap I_k}\cong\bigslant{A}{\prod I_k}\cong \prod \bigslant{A}{I_k}
\]
\end{theorem}

\begin{proof}
If $\pi$ is surjective $\implies$ $\exists a_i$ such that $\pi(a_i)=(0,\cdots,0,1,0,\cdots,0)$, $1$ on the $i$-th place. $a_i\in I_j$ and $1-a_i\in I_i$ for $j\neq i$ $\implies$ $I_i$ is relatively prime to any $I_j$ (since $1 = (1-a_i) + a_i$).

Conversely, suppose that the ideals are relatively prime. This implies that $I_i$
is relatively prime to $\prod_{i\neq j} I_j$. 

$\exists x_i \in I_i$, $y_i \in \prod_{j\neq i} I_j$ such that $x_i + y_i = 1$. And such an element $y_i$ maps to $\pi(a_i)=(0,\cdots,0,1,0,\cdots,0)$, $1$ on the $i$-th place.
$\sum_{i=1}^n b_iy_i\mapsto(b_1,\cdots,b_n)$, $\forall b$'s. So the map is surjective.

\end{proof}

Consider $A$ finite algebra over $K$. Before proving a general theorem on the structure of $A$, we state a proposition. 

\begin{proposition}
\begin{enumerate}
\item If $A$ is an integral domain (no zero divisors) $\implies$ $A$ is a field.
\item (rephrasing) Any prime ideal of $A$ is maximal. 
\end{enumerate}
\end{proposition}

\begin{proof}
We prove only the first part: the second part is a consequence of definitions. In fact, a  quotient over a prime ideal is an integral domain, and a quotient over a maximal ideal is a field. (Reference: Atiyah  \& Macdonald, Introduction to commutative algebra.)

First part: What means, that is an integral domain? Integral domain,no zero divisors, means that the multiplication made by any element $a$ is injective. $A$ is a finite-dimensional $K$-vector space which is surjective. $\implies$ the multiplication by $a$ is an isomorphism. In particular, it is surjective.$\implies$, $\exists b$ such that $b \times a = 1$. Which means that $A$ is a field.
\end{proof}

\section{Structure of finite algebras over a field. Examples}

\begin{theorem} \textbf{Structure of finite K algebras.} Let $A$ be a finite $K$-algebra:  $A$ is a finite dimensional $K$ vector space. Then:
\begin{enumerate}
\item There are only finitely many maximal ideals $m_1, \cdots m_r$ in A.
\item $J=\cap m_i=\prod m_i$ (they are relatively prime). Then $J^n= 0$ for some $n$. 
\item $A\cong A/m_1^{n_1}\times\cdots\times A/m_r^{n_r}$ (isomorphic) for some $n_1,\cdots,n_r$.
\end{enumerate}
\end{theorem}

\begin{proof}
Part 1. Let $m_1,\cdots m_i$ be maximal ideals. By Chinese remainder theorem we have $A/\prod m_j\cong A/m_1\times\cdots A/m_i$ (isomorphic).  $A/\prod^i_1 m_j$ and $A/mj$ are finite dimensional $K$-vector spaces.  $\text{dim}_KA\geq \text{dim}_KA/\prod^i_1 m_j=\sum \text{dim}_KA/m_j\geq i$ $\implies$ the number of maximal ideas is $\leq \text{dim}_KA$

Part 2. $J$ is also a finite dimensional $K$-vector space and so are it's powers. Consider the following sequence. $J\supseteq J^2\supseteq J^3\supseteq \cdots \supseteq J^k \supseteq \cdots$ (a decrease in sequence of finite dimensional vector spaces. The dimension decreases as $k$ increases.) This sequence must stabilize. $\exists n$ such that $J^n=J^{n + 1}$. We claim that in this case $J^n= 0$. Indeed, if not, let $e_1,\cdots e_s$ be a basis of $J^n$. As $J^n=J\cdot J^n$, we can write $e_i=\sum\lambda_{ij} e_j$, for $\lambda_{ij}\in J$. If we consider the matrix $M=\mathds{1} -\lambda_{ij}$, we have that $M \cdot (e_1,\cdots,e_s)^T=0$. Since M is a matrix over a ring and not over a field, this does not immediately mean that the i's are zero but we can always find the matrix $\widetilde{M}$ such that $\widetilde{M}M=\text{det}(M)\cdot\mathds{1}$. This is possible over a ring. So the corollary is that the $\text{det}(M)\cdot (e_1,\cdots,e_s)^T=0$. $\text{det}(M)=1 + \lambda$, where $\lambda \in J$. Since $J=m_1\cap\cdots\cap m_j$ (intersection of all maximal ideals), $\lambda \in m_i$ $\forall i$. So, $1 + \lambda$ is no maximal ideal, $\nexists i, 1+\lambda\in m_i$ $\implies$ $1 + \lambda$ is invertible $\implies$ $e_i=0$. So this is a contradiction. 

Part 3. By part 2, we can find $n_1,\cdots n_r$ such that $n_1^{n_1}\cdot\cdots\cdot n_r^{n_r}=0$. (for instance take all $n_i=n$). Then by Chinese remainder theorem, $A\cong A/m_1^{m_1}\times\cdots A/m_r^{m_r}$. Since $A=A/m_1^{m_1}\cdots A/m_r^{m_r}$, where $m_i^{m_i}$ are pairwise relatively prime. So this proves the theorem. 
\end{proof}

Remark. The $n_i$'s are not uniquely determined. For instance, $A=K[x]/(x^2\cdot(x+1)^3)$ . Then we have two maximal ideals. $m_1=(x)$ and $m_2 =(x + 1)$. Then $A = A/m_1 ^2\times A/m_2 ^3$ but also $A\cong A/m_1 ^3 \times A/ m_2 ^3$. Reason: $m_1^2= m_1^3$. In $A$ the ideal $(x)^2\supset (x)^3$, but also, the converse is true. This is not true in
the polynomial ring but it is true in A (verification as an exercise).

Examples of finite dimensional K algebras. 
\begin{example}
$\mathbb{C}\otimes_{\mathbb{R}}\mathbb{C}=\mathbb{C}\times\mathbb{C}$. 
$\mathbb{Q}(\sqrt{2})\otimes_{\mathbb{Q}}\mathbb{Q}(\sqrt{3})=\mathbb{Q}(\sqrt{2},\sqrt{3})$. All these algebras are products of fields: all $n_i=1$. In other words, we don't have nilpotents in our algebra. Reduced algebras (by definition  without nilpotents).
\end{example}

In the next lecture, you will see that this is a general phenomenon. The presence of nilpotents is due to the inseparability of extensions.